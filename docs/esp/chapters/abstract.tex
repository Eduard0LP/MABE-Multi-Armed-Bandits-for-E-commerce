% Preamble
\documentclass[../main.tex]{subfiles}

% Document
\begin{document}
\chapter*{Abstract}\label{ch:abstract}

This document addresses the multi-armed bandit problem, focusing on the main
algorithms traditionally used to solve it and their possible applications in real-world
environments. The algorithms discussed are $\epsilon$-Greedy, Upper Confidence Bound,
Thompson Sampling, Linear Upper Confidence Bound, and Linear Thompson
Sampling, and they are applied to the practical case of an e-commerce platform,
which have become increasingly relevant with the digitization of our society. The
accuracy of the recommendations made by the aforementioned algorithms is
analysed based on whether or not users click on the products suggested by the
algorithm. The increase in the accuracy of the recommendations when the user's
context is considered to make suggestions is highlighted, and the possibility of using
deep learning-based models to further improve the system's recommendations is
discussed, which is left for future work.

\textbf{Keywords}: multi-armed bandit, $\epsilon$-Greedy, Upper Confidence Bound, 
Thompson Sampling, Linear Upper Confidence Bound, Linear Thompson Sampling, reward,
regret, e-commerce.

\end{document}